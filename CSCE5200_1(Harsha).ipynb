{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 26,
      "metadata": {
        "id": "V1F5aMGJVlQs",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c21d9665-52b5-4063-8a19-33296b2f3250"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Package punkt is already up-to-date!\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 26
        }
      ],
      "source": [
        "# Importing the require Libraries\n",
        "import os\n",
        "from collections import Counter\n",
        "from nltk.tokenize import word_tokenize\n",
        "import nltk\n",
        "nltk.download('punkt')"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#convert text to lowercase\n",
        "def lowercase(text):   \n",
        "    text=text.lower()\n",
        "    return text\n",
        "\n",
        "# path to the files\n",
        "path= '/content/sample_data/filesx' \n",
        "files = dict()\n",
        "inverted_index = {}\n",
        "\n",
        "#iterate through all the files in the given path\n",
        "for filename in os.listdir(path):           \n",
        "    files_to_read = path + \"/\" + filename    \n",
        "    fileslist = open(files_to_read, \"r\", encoding=\"utf-8\")\n",
        "    corpus = fileslist.read()\n",
        "    corpus = lowercase(corpus)\n",
        "\n",
        "    #read the stop words\n",
        "    stopfile = open('/content/sample_data/stop_words.txt', encoding='utf8')\n",
        "    stop_words = stopfile.read()\n",
        "\n",
        "    #split the content into tokens\n",
        "    text_tokens = word_tokenize(corpus)\n",
        "\n",
        "    #remove punctuations from the tokens\n",
        "    text_tokens = [word.strip('''!()-[]{};:'\"\\, <>./?@#$%^&*_~''') for word in text_tokens]\n",
        "    text_tokens = [word.replace(\"'s\", '') for word in text_tokens]\n",
        "\n",
        "    #remove stop words from the tokens\n",
        "    text_tokens =  [word for word in text_tokens if not word in stop_words]\n",
        "    \n",
        "    \n",
        "    for word in text_tokens:\n",
        "     if word in inverted_index:\n",
        "        inverted_index[word].add(filename)\n",
        "     else: inverted_index[word] = {filename}\n",
        "\n",
        "#inverted_index"
      ],
      "metadata": {
        "id": "MZRWcZtFOH9_"
      },
      "execution_count": 34,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#User Input\n",
        "try:\n",
        "  input_string = input(\"Enter your Search Term:\\n\\n\")\n",
        "  input_string = lowercase(input_string)\n",
        "\n",
        "  print(\"The Search term is in Documents\\n\",inverted_index[input_string])\n",
        "  #print(inverted_index[input_string])\n",
        "\n",
        "except:\n",
        "  print(\"\\nThe SEARCH WORD IS NOT PRESENT IN THE INVERTED INDEX\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sxp8fnx8GL1H",
        "outputId": "3f91f851-63b3-48e5-f77e-dfda96917adb"
      },
      "execution_count": 38,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Enter your Search Term:\n",
            "\n",
            "a\n",
            "\n",
            "The SEARCH WORD IS NOT PRESENT IN THE INVERTED INDEX\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "P0Log3rROBpJ"
      },
      "execution_count": 28,
      "outputs": []
    }
  ]
}